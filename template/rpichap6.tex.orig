%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                 %
%                            CHAPTER SIX                          %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

<<<<<<< HEAD
\chapter{FUTURE WORK}\label{ch:future}

A number of concerns were not addressed during the versioning graph research process.
Since a new change statement is made for each difference between versions, some optimizations must be made to keep version graphs small enough to be encoded within change logs.
Discontinuous attributes across multi-version graphs creates a problematic barrier to graph queries.
Finally, further study must be done to determine methods in providing quantitative basis for version identifiers.
These un-addressed questions form the most immediately approachable next steps for this versioning graph approach.

Very large change logs encoded with JSON-LD through HTML began experiencing performance issues due to the extreme number of modifications in the graph.
One observation is that a modification in one cell of the Noble Gas data set sometimes also occurs in every other cell in that spreadsheet column.
The relation of all those cells could then be summarized with a singe modification statement with just the column attribute, reducing the space utilization dependency from the number of rows to a single statement.
The summarization could reduce the change log's size to a manageable enough level to be viewable.

At present, the versioning model captures only changing as a matter of convention and to save space.
Version graphs with multiple versions can suffer discontinuities across attributes which don't change between two versions, but then experience a modification later.
Discontinuities in the graph causes problems for search queries since a directed path does not exist through all versions in the graph for that attribute.
The definition of a null-step to bridge gaps could provide a temporary solution to show an attribute in the graph hasn't changed but re-establish connectivity.
The addition could also introduce new space utilization concerns.

The initial research to study the relationship between change counts and version identifiers broke down due to the subjectivity of identifier assignment.
Not enough evidence was found to determine if identifiers were assigned accurately.
Applying the versioning model to more data sets and comparing change counts may be necessary to determine what quantifiable methods, if any, can be used as a basis for version identifier assignment.
The research would be conducted to determine the extent to which dot-decimal identifiers can communicate change of a data set.

Future work should be conducted to reduce the size of change logs, re-connect multi-version graphs, and determine a quantitative basis for version identifiers.
Change logs can be shortened by discovering modifications occurring over an entire column which can be summarized in a single statement.
Null-step links could be used to reconnect attributes in multi-version graphs, but this may also introduce new space consumption issues.
The versioning model should be applied to more data sets employing the dot-decimal identifier method to gather evidence on the extent to which the identifiers can communicate change in a data set.
These approaches were left unexplored by the project's conclusion.
=======
\chapter{MBVL CLASSIFICATION}\label{ch:mbvl`}

The goal of this section is to use the versioning graph to compare the accuracy of different algorithm and taxonomy combinations in determining the taxonomic classification of marine microbiological species.

\section{Versioning Graph}

The experiment undergoes two phases of comparison in this procedure.
The first phase compares the initial species content with the classifications by a particular algorithm/taxonomy combination.
Since the classification results from a population selected according to the initial species list, these two datasets share a common provenance.
The list, however, cannot be used in place of the classifier results because not only does it have only 21 entries, but also it does not have a clear correspondence with the DNA chains sent to the classifier.
As a result, these two sets are not versions of each other, and versioning results will have weak implications.
A labeling of the initial input data, could be considered a version of the results, but that data product is not available.

Each taxonomy and classifier combination outputs a taxonomic classification for each entry from the same source.
Shared input data indicates the results share common provenance.
The classifications also share the same workflow step because their results have similar formats, reporting a specific taxonomic name for each entry.
Since classifications occur over the same set of entries, their identifiers can be used to match outputs together for comparison.
If this method of matching, however, is used, every mapping would be a modification since each identifier appears in all data sets, and it would not provide any comparison based on the algorithm's specificity.
Instead, a mapping using the accuracy of each algorithm is used.
Since a name is assigned at a taxonomic rank to a sequence only if it passes the algorithm's confidence level, matches can be determined on whether a classifier can confidently decide more or fewer ranks.
As a result, additions and invalidations ascertain whether a classifier can identify more or less of an entry's taxonomic name while modifications indicate the same specificity but mismatching names.
This method of mapping versions allows the results to give insight into the accuracy of different algorithm and taxonomy combinations.

\section{Analysis}

Figure \ref{mbvl_chart} shows the results of four comparisons performed using the matching procedure in the previous section.
There are only four comparisons because varying both taxonomy and algorithm muddles the contribution of each towards a more accurate result.
In the first set of columns, the Silva taxonomy results are versioned against RDP using the Spingo algorithm.
The naming reflects the orientation in the versioning graph so Silva forms the left-hand version and RDP would be the right-hand version.
In this comparison, using the RDP taxonomy seems to provide more accurate results, most specifically at the species level.
The taxonomies also disagree fairly often at the species and family ranks.
Switching to the Gast algorithm in the second set of columns, RDP once again demonstrates a noticeably greater accuracy in species classification.
There are also significantly fewer disagreements using the Gast algorithm between the two taxonomies.
Looking at the third set of columns, Silva demonstrates greater accuracy classifications under the Spingo algorithm than under Gast.
Over four thousand of these entries can be classified to the species level when Gast cannot.
In the fourth set of columns, RDP appears to perform better with Spingo than Gast.
The comparison, however, is dominated by a much larger number of disagreements between almost six thousand entries, primarily at the species rank.
On closer inspection, this disagreement is explained by Gast classifying the species for a number of entries as unclutured bacterium.
This analysis presents evidence that using the RDP taxonomy with the Spingo algorithm will produce the most accurate classification results.

\begin{figure}
	\centering
	\includegraphics[scale=0.80]{figures/mbvl_chart.png}
	\caption{Compiled counts of adds, invalidates, and modifies grouped by taxonomic rank across algorithm and taxonomy combinations.}
	\label{mbvl_chart}
\end{figure}
>>>>>>> master
