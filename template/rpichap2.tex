%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                 %
%                            CHAPTER TWO                          %
%                                                                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{PREVIOUS WORK}
%\resetfootnote %this command starts footnote numbering with 1 again.
Early work in the field of digital data versioning begins in the library sciences.
As the computing field grows, many data publications are now being provided in digital formats as well as print.
The challenges of tracking a digital library are often the same as those faced in data repository management \cite{Wiil:2000:RDH:338407.338517}.
Not only do librarians often have to simultaneously work with several versions of the same material, but they also must pay attention to the structure of their collection as well as its content.
Digital Object Identifiers (DOI) and other identifiers evolved to help digitally track the growing number of electronic documents.
They have also been used to track and cite datasets, but unlike documents, datasets have a tendancy to change after publication.
As a result, new versions of data would get a new DOI to prevent confusion, and this unnecessarily consumes the available handles and the time of institutions assigning handles \cite{Lyons2005}.
Other identifier systems have also had problems with maintaining healthy links to data as it changes and moves, but systems using newer technology have been able to achieve success in localized networks.
Built on XML and web service technology, the Mellon Fedora project linked together various disparate digital library collections at the University of Virginia  \cite{Payette2002}.
Digital publications not only include books and journals, but also grew to include web pages and wikis, requiring new scalable methods to track changes on these publications \cite{Berberich:2007:TMT:1277741.1277831}.

Many organizations rely on databases to provide large segments of data to their consumers.
Various methods have been studied to manage changes within these systems focusing primarily on schema versioning, emphasizing data's structural component \cite{roddick1996model}.
The framework of the resulting database environment can become quite complicated as a result of the complexity of the tables representing intricate data objects \cite{Klahold:1986:GMV:645913.671314}.
More recently, new methods have been developed to adjust to the enormous quantities of data populating modern databases \cite{Proell2013} \cite{DBLP:conf/data/2013}.
The focus for this method emphasizes the focus on scalability of solutions and notes that a significant challenge to proper data referencing is proper subset description \cite{proellBigData}.
The solution suggested by Proell suggests that some of the complexities of the system structure can be abstracted through the query language.

\section{Unifying multiple systems}
\subsection{Grid}
In the early 2000s, versionings systems were being prepared for the future of grid technologies.
The grid provided a unique environment that had to handle a variety of inputs, and therefore, different input data could run on distinct sets of grid services.
This meant that different versions of the same data could be generated by differing services on the same grid \cite{Kovse2003VGridAVS}.
A versioning environment would also have to be general enough to accommodate disparate input types.
CERN grid for the Compact Muon Solenoid experiment separates the physical and logical storage of files, allowing multiple users to refer to the same file without needing to copy the file across the grid \cite{Holtman:687353}.
Versioning policy could not exist in this case if a clear replication policy did not exist since changes to the underlying file can have repercussions with its replications across the grid.
The versioning method relies on predictable replication in order to reliably communicate change to grid users.
\subsection{Heterogeneous systems}
While innovative, the grid was neglected in favor of networked heterogeneous systems.
The proliferation of mobile computational devices such as laptops and smart phones created a supply of small data repositories that were too compact to warrant the use of grid technologies.
Baker and Yarmey describe a method of networking together small, volatile datasets with larger, versioned data distribution centers for environmental data \cite{Baker2009}.
Heterogeneous systems encounter challenges with data integration resulting from non-uniform data interfaces.
Autonomous solutions to understanding change grows in importance as evidence grows that speedy and relevant changes play a significant role in successful system function \cite{Bouzeghoub:2004:FAD:1012453.1012464}.
The key often seems to be using XML to provide an common language propagating change across heterogenous systems.
The need to propagate changes becomes more apparent as autonomous units grow and share data \cite{Systems02champagne:data}.
Semantic technology's growth now provides a new method of propagating data change that can not only be universally consumed in formats like XML but also encodes meaning to each of these changes.

\subsection{Ontologies}
The web also provides a new venue for computational versioning in addition to offering a new means to communicate change.
Machine readable vocabularies are maintained in large data collections known as ontologies.
As the language improves and the vocabulary refines concepts, ontology versioning becomes a vital component in its growth.
Previous work has emphasized the importance of making data not only backwards compatible to provide comparisons, but also forward compatible such that applications can seamlessly migrate from older concepts to newer ones \cite{Klein01ontologyversioning}.

PROV is a W3C recommendation that deliniates a method to express data provenance with semantic technologies \cite{Belhajjame2013}.
Using the model of relating activities, agents, and entities, data managers can express the origins of their datasets.
However, when an entity is revised, the PROV data model can only express the relationship as a revision or that the new dataset was derived from the original.
This leaves



%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
